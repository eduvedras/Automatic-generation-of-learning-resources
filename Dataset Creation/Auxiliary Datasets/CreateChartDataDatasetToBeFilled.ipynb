{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, to_datetime, to_numeric\n",
    "import os\n",
    "\n",
    "def get_variable_types(df: DataFrame) -> dict[str, list]:\n",
    "    variable_types: dict = {\"numeric\": [], \"binary\": [], \"date\": [], \"symbolic\": []}\n",
    "\n",
    "    nr_values: Series = df.nunique(axis=0, dropna=True)\n",
    "    for c in df.columns:\n",
    "        if 2 == nr_values[c]:\n",
    "            variable_types[\"binary\"].append(c)\n",
    "            df[c].astype(\"bool\")\n",
    "        else:\n",
    "            try:\n",
    "                to_numeric(df[c], errors=\"raise\")\n",
    "                variable_types[\"numeric\"].append(c)\n",
    "            except ValueError:\n",
    "                    variable_types[\"symbolic\"].append(c)\n",
    "\n",
    "    return variable_types\n",
    "\n",
    "classes = {'adult': ['income'],'BankNoteAuthentication': ['class'],\n",
    "           'Breast_Cancer': ['diagnosis'], 'Churn_Modelling': ['Exited'],\n",
    "           'diabetes':['Outcome'], 'heart': ['target'], 'Iris': ['Species'],\n",
    "           'Titanic': ['Survived'], 'Wine': ['Class'], 'WineQT': ['quality'],\n",
    "           'vehicle': ['target'], 'apple_quality': ['Quality'], 'loan_data': ['Loan_Status'],\n",
    "           'credit_customers': ['class'], 'smoking_drinking': ['DRK_YN'], 'sky_survey': ['class'],\n",
    "           'weatherAUS': ['RainTomorrow'], 'Dry_Bean_Dataset': ['Class'],'abalone': ['Sex'],\n",
    "           'car_insurance': ['is_claim'], 'Covid_Data': ['CLASSIFICATION'],'customer_segmentation': ['Segmentation'],\n",
    "           'detect_dataset': ['Output'],'e-commerce': ['ReachedOnTime'], 'Employee': ['LeaveOrNot'],\n",
    "           'Hotel_Reservations': ['booking_status'], 'Liver_Patient': ['Selector'], 'maintenance': ['Machine_failure'],\n",
    "           'ObesityDataSet': ['NObeyesdad'], 'phone': ['price_range'], 'Placement': ['status'],\n",
    "           'StressLevelDataset': ['stress_level'], 'urinalysis_tests': ['Diagnosis'], 'water_potability': ['Potability']}\n",
    "\n",
    "conditions = {'adult':['hours-per-week <= 41.5','capital-loss <= 1820.5'], 'BankNoteAuthentication':['skewness <= 5.16','curtosis <= 0.19'],\n",
    "                'Breast_Cancer':['perimeter_mean <= 90.47','texture_worst <= 27.89'],'Churn_Modelling':['Age <= 42.5','NumOfProducts <= 2.5'],\n",
    "                'diabetes':['BMI <= 29.85','Age <= 27.5'],'heart':['slope <= 1.5','restecg <= 0.5'],\n",
    "                'Titanic':['Pclass <= 2.5','Parch <= 0.5'],'vehicle':['MAJORSKEWNESS <= 74.5','CIRCULARITY <= 49.5'],\n",
    "                'Wine':['Total phenols <= 2.36','Proanthocyanins <= 1.58'],'WineQT':['density <= 1.0','chlorides <= 0.08'],\n",
    "                'apple_quality':['Juiciness <= -0.3','Crunchiness <= 2.25'],'loan_data':['Loan_Amount_Term <= 420.0','ApplicantIncome <= 1519.0'],\n",
    "                'credit_customers':['existing_credits <= 1.5','residence_since <= 3.5'],'smoking_drinking':['SMK_stat_type_cd <= 1.5','gamma_GTP <= 35.5'],\n",
    "                'sky_survey':['dec <= 22.21','mjd <= 55090.5'],'weatherAUS':['Rainfall <= 0.1','Pressure3pm <= 1009.65'],\n",
    "                'Dry_Bean_Dataset':['Area <= 39172.5','AspectRation <= 1.86'],'abalone':['Height <= 0.13','Diameter <= 0.45'],\n",
    "                'car_insurance':['displacement <= 1196.5','height <= 1519.0'],'Covid_Data':['CARDIOVASCULAR <= 50.0','ASHTMA <= 1.5'],\n",
    "                'customer_segmentation':['Family_Size <= 2.5','Work_Experience <= 9.5'],'detect_dataset':['Ic <= 71.01','Vb <= -0.37'],\n",
    "                'e-commerce':['Prior_purchases <= 3.5','Customer_care_calls <= 4.5'],'Employee':['JoiningYear <= 2017.5','ExperienceInCurrentDomain <= 3.5'],\n",
    "                'Hotel_Reservations':['lead_time <= 151.5','no_of_special_requests <= 2.5'],'Liver_Patient':['Alkphos <= 211.5','Sgot <= 26.5'],\n",
    "                'maintenance':['Rotational speed [rpm] <= 1381.5','Torque [Nm] <= 65.05'],'ObesityDataSet':['FAF <= 2.0','Height <= 1.72'],\n",
    "                'phone':['int_memory <= 30.5','mobile_wt <= 91.5'],'Placement':['ssc_p <= 60.09','hsc_p <= 70.24'],\n",
    "                'StressLevelDataset':['basic_needs <= 3.5','bullying <= 1.5'],'urinalysis_tests':['Age <= 0.1','pH <= 5.5'],\n",
    "                'water_potability':['Hardness <= 278.29','Chloramines <= 6.7'],'Iris':['PetalWidthCm <= 0.7','PetalWidthCm <= 1.75']}\n",
    "\n",
    "neighbors = {'abalone': ['932','117','683','1191'],'adult':['21974','541','9274','434'],\n",
    "             'apple_quality': ['148','784','1625','243'],'BankNoteAuthentication': ['214','436','179','131'],\n",
    "             'Breast_Cancer': ['184','50','20','144'],'car_insurance': ['2141','686','774','3813'],\n",
    "             'Churn_Modelling': ['4831','114','1931','124'],'Covid_Data': ['173','7971','16','46'],\n",
    "             'credit_customers': ['264','183','146','107'],'customer_segmentation': ['249','524','723','11'],\n",
    "             'detect_dataset': ['797','6394','3','1206'],'diabetes': ['111','98','167','161'],\n",
    "             'Dry_Bean_Dataset': ['760','2501','4982','1284'],'e-commerce': ['3657','906','1540','1596'],\n",
    "             'Employee': ['1781','1215','44','217'],'heart': ['202','181','137','197'],'Hotel_Reservations': ['10612','9756','4955','69'],\n",
    "             'Iris': ['35','38','32'],'Liver_Patient': ['77','125','109','94'],'loan_data': ['3','204','2','6'],\n",
    "             'maintenance': ['943','46','21','5990'],'ObesityDataSet': ['840','370','107','160'],'phone': ['469','209','86','636'],\n",
    "             'Placement': ['16','20','68','46'],'sky_survey': ['208','11119','945','1728'],'smoking_drinking': ['7218','1796','3135','2793'],\n",
    "             'StressLevelDataset': ['271','240','223','36'],'Titanic': ['181','72','188','57'],'urinalysis_tests': ['3','23','215','763'],\n",
    "             'vehicle': ['1','2','3','4'],'Wine': ['305','109','53','125'],'water_potability': ['8','1388','5','6'],\n",
    "             'weatherAUS':['1154','1686','251','608'],'Wine':['49','12','2','60'],'WineQT':['154','27','172','447']}\n",
    "\n",
    "directory = '/home/eduvedras/tese/templates/datasets/'\n",
    "\n",
    "variable_types = {}\n",
    "\n",
    "data = pd.read_csv(\"chartdata.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.DataFrame(columns=['Id','Data','Chart'])\n",
    "for index,row in data.iterrows():\n",
    "    possible_name = row['Chart'].split(\"_\")\n",
    "    if possible_name[0] in classes.keys():\n",
    "        dataset = pd.read_csv(directory + f\"{possible_name[0]}.csv\")\n",
    "        filename = possible_name[0]\n",
    "    elif possible_name[0] + \"_\" + possible_name[1] in classes.keys():\n",
    "        dataset = pd.read_csv(directory + possible_name[0] + \"_\" + possible_name[1]+ \".csv\")\n",
    "        filename = possible_name[0] + \"_\" + possible_name[1]\n",
    "    \n",
    "    types = get_variable_types(dataset)\n",
    "    if 'boxplots' in row['Chart']:\n",
    "        aux = \"[F,{\"\n",
    "        for var in types[\"numeric\"]:\n",
    "            aux += var + \":{Outliers:,Balanced:\" + \"},\" \n",
    "        aux = aux[:-1] + \"}\" + \"]\"  \n",
    "        new_row = {'Id':row['Id'],'Data': aux,'Chart': row['Chart']}\n",
    "    elif 'histograms_numeric' in row['Chart']:\n",
    "        aux = \"{\"\n",
    "        numeric = types[\"numeric\"]\n",
    "        if classes[filename][0] in numeric:\n",
    "            numeric.remove(classes[filename][0])\n",
    "        for var in numeric:\n",
    "            min = dataset[var].min()\n",
    "            max = dataset[var].max()\n",
    "            aux += var + \":{Outliers:,Balanced:,Range:[\" + f\"{min},{max}]\" + \"},\"\n",
    "        aux = aux[:-1] + \"}\"\n",
    "        new_row = {'Id':row['Id'],'Data': aux,'Chart': row['Chart']}\n",
    "    elif 'histograms_symbolic' in row['Chart']:\n",
    "        aux = \"{\"\n",
    "        symbolic = types['symbolic'] + types['binary']\n",
    "        if classes[filename][0] in symbolic:\n",
    "            symbolic.remove(classes[filename][0])\n",
    "        \n",
    "        for var in symbolic:\n",
    "            l = [x for x in dataset[var].unique().tolist() if str(x) != 'nan']\n",
    "            aux += f\"{var}:{l},\"\n",
    "        aux = aux[:-1] + \"}\"\n",
    "        new_row = {'Id':row['Id'],'Data': aux,'Chart': row['Chart']}\n",
    "    elif 'mv' in row['Chart']:\n",
    "        mv: dict[str, int] = {}\n",
    "        for var in dataset.columns:\n",
    "            nr: int = dataset[var].isna().sum()\n",
    "            if nr > 0:\n",
    "                mv[var] = nr\n",
    "        new_row = {'Id':row['Id'],'Data': mv,'Chart': row['Chart']}\n",
    "    elif 'overfitting' not in row['Chart'] and 'decision_tree' in row['Chart']:\n",
    "        if len(neighbors[filename])==4:\n",
    "            aux = {conditions[filename][0]:{'samples':int(neighbors[filename][0])+int(neighbors[filename][1])+int(neighbors[filename][2])+int(neighbors[filename][3]),'value':[],'class':'',\n",
    "                'True':{conditions[filename][1]:{'samples':int(neighbors[filename][0])+int(neighbors[filename][1]),'value':[],'class':'','True':{'samples':int(neighbors[filename][0]),'value':[],'class':''},'False':{'samples':int(neighbors[filename][1]),'value':[],'class':''}}},\n",
    "                'False':{conditions[filename][1]:{'samples':int(neighbors[filename][2])+int(neighbors[filename][3]),'value':[],'class':'','True':{'samples':int(neighbors[filename][2]),'value':[],'class':''},'False':{'samples':int(neighbors[filename][3]),'value':[],'class':''}}}}}\n",
    "        elif len(neighbors[filename])==3:\n",
    "            aux = {conditions[filename][0]:{'samples':int(neighbors[filename][0])+int(neighbors[filename][1])+int(neighbors[filename][2]),'value':[],'class':'',\n",
    "                'True':{'samples':int(neighbors[filename][0]),'value':[],'class':''},\n",
    "                'False':{conditions[filename][1]:{'samples':int(neighbors[filename][1])+int(neighbors[filename][2]),'value':[],'class':'','True':{'samples':int(neighbors[filename][1]),'value':[],'class':''},'False':{'samples':int(neighbors[filename][2]),'value':[],'class':''}}}}}\n",
    "        new_row = {'Id':row['Id'],'Data': aux,'Chart': row['Chart']}\n",
    "    else:\n",
    "        new_row = {'Id':row['Id'],'Data': row['Data'],'Chart': row['Chart']}\n",
    "    new_dataset.loc[len(new_dataset)] = new_row\n",
    "    \n",
    "#new_dataset.to_csv(\"chartdatatest.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     numeric\u001b[38;5;241m.\u001b[39mremove(classes[filename][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m numeric:\n\u001b[0;32m---> 23\u001b[0m     l \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(l) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m     25\u001b[0m         ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"chartdatatest.csv\",sep=\";\")\n",
    "new_dataset = pd.DataFrame(columns=['Id','Data','Chart'])\n",
    "\n",
    "for index,row in dataset.iterrows():\n",
    "    possible_name = row['Chart'].split(\"_\")\n",
    "    if possible_name[0] in classes.keys():\n",
    "        dataset = pd.read_csv(directory + f\"{possible_name[0]}.csv\")\n",
    "        filename = possible_name[0]\n",
    "    elif possible_name[0] == 'Dry':\n",
    "        dataset = pd.read_csv(directory + \"Dry_Bean_Dataset.csv\")\n",
    "        filename = 'Dry_Bean_Dataset'\n",
    "    elif possible_name[0] + \"_\" + possible_name[1] in classes.keys():\n",
    "        dataset = pd.read_csv(directory + possible_name[0] + \"_\" + possible_name[1]+ \".csv\")\n",
    "        filename = possible_name[0] + \"_\" + possible_name[1]\n",
    "        \n",
    "    types = get_variable_types(dataset)\n",
    "        \n",
    "    if 'histograms_numeric' in row['Chart']:\n",
    "        aux = row['Data']\n",
    "        numeric = types[\"numeric\"]\n",
    "        if classes[filename][0] in numeric:\n",
    "            numeric.remove(classes[filename][0])\n",
    "        for var in numeric:\n",
    "            l = [x for x in dataset[var].unique().tolist() if str(x) != 'nan']\n",
    "            if len(l) <= 10:\n",
    "                ans = 'T'\n",
    "            else:\n",
    "                ans = 'F'\n",
    "            spl = aux.split(\"Range:[\",1)\n",
    "            aux = spl[0] + \"Ordinal:\" + ans + spl[1].split(\"]\",1)[1]\n",
    "                \n",
    "        new_row = {'Id':row['Id'],'Data': aux,'Chart': row['Chart']}\n",
    "    else:\n",
    "        new_row = {'Id':row['Id'],'Data': row['Data'],'Chart': row['Chart']}\n",
    "    new_dataset.loc[len(new_dataset)] = new_row\n",
    "    \n",
    "new_dataset.to_csv(\"example.csv\",sep=\";\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
