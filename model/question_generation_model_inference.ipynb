{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('eduvedras/Img_Desc',split='test',trust_remote_code=True)\n",
    "\n",
    "image = dataset[0]['Chart']\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "checkpoint = \"google/pix2struct-textcaps-base\"\n",
    "from transformers import AutoProcessor\n",
    "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\n",
    "\n",
    "processor = Pix2StructProcessor.from_pretrained(checkpoint)\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "flattened_patches = inputs.flattened_patches\n",
    "attention_mask = inputs.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_templates = Pix2StructForConditionalGeneration.from_pretrained(\"eduvedras/pix2struct-textcaps-base-desc-templates-final\").to(device)\n",
    "model_vars = Pix2StructForConditionalGeneration.from_pretrained(\"eduvedras/pix2struct-textcaps-base-desc-vars-final\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_template_ids = model_templates.generate(flattened_patches=flattened_patches, attention_mask=attention_mask, max_length=193)\n",
    "generated_template = processor.batch_decode(generated_template_ids, skip_special_tokens=True)[0]\n",
    "print(generated_template)\n",
    "\n",
    "generated_vars_ids = model_vars.generate(flattened_patches=flattened_patches, attention_mask=attention_mask, max_length=167)\n",
    "generated_vars = processor.batch_decode(generated_vars_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(generated_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generated_template.replace(\"[]\",\"[\" + generated_vars + \"]\")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
